#!/usr/bin/env python2
# vim:fileencoding=utf-8
from calibre import strftime
from calibre.web.feeds.recipes import BasicNewsRecipe
from mechanize import Request
import json


class Tabltalk(BasicNewsRecipe):

    appURL = 'https://tabletalkmagazine.com/'
    title = 'Tabletalk'
    publisher = 'Ligonier Ministries'
    __author__ = 'pieplu'
    description = 'Download the Tabletalk magazine of the current month'
    needs_subscription = False
    no_stylesheets = True

    conversion_options = {'publisher': publisher}

    timefmt = ' - %B %Y'
    remove_tags = [dict(attrs={'class':['social-share', 'share-buttons', "social-share naked-social-share","share-buttons share-buttons--footer","naked-social-share", "social-share__icons", 'article__number']}),
                dict(id=['footer']),
                dict(name=['script', 'noscript', 'header', 'style'])]
    remove_tags_after = [dict(attrs={'class':['post-content-wrapper']})]
    extra_css = ('.tt-quote{font-weight:bolder;font-size:1.2em;text-align:center;}'
                '.article__footer{text-align:center;font-size:.9em;}.article__footer:before{content:"";width:4em;height:.2em;display:block;background:#D3D0CC}'
                '.article__number{color:#D3D0CC;font-family:sans-serif;}.article__number p{display:inline-block;}'
                '.header-base__column{display:inline-block;font-family:sans-serif;}.header-base__column--first{padding-right:1em;}'
                'h5{text-transform:uppercase;font-size:1em;color:#444444}'
                'img{max-width:100%}')


    def getIssueJson(self, issueId):
        br = BasicNewsRecipe.get_browser(self)
        post_url = self.appURL + "/wp-admin/admin-ajax.php"
        payload = {
            'id' : issueId + "",
            'action':'issue_toc',
            'dataType':'json'
        }
        headers = {
            'cache-control': "no-cache",
            'X-HTTP-Method-Override': 'POST',
            'X-Requested-With': 'XMLHttpRequest'
            }
        rq = Request(post_url, headers=headers, data=payload)
        r = br.open(rq)
        if r.code != 200:
            raise ValueError('Failed POST request')
        return json.loads(r.read())


    def parse_index(self):
        baseURL = self.appURL
        soup = self.index_to_soup(baseURL + "magazine/")
        features = []
        columns = []
        dailystudies = []
        issueName = ""
        ans = []
        issueId = 0

        issueId = soup.find('div', attrs={"data-issue-id": True})["data-issue-id"]
        data = self.getIssueJson(issueId)

        issueName = data.get("issue_title")
        self.title = issueName + ' - Tabletalk'
        self.cover_url = data.get("issue_image")
        self.description = data.get("issue_date") + " - " + data.get("issue_link")

        for featuredArticle in data.get("featured_articles"):
            url = featuredArticle["post_link"]
            title = featuredArticle["post_title"]
            author = featuredArticle["post_author"]
            description = ''
            pubdate = data.get("issue_date")
            features.append(
                dict(title=title, url=url, date=pubdate, description=description, content='', author=author))

        for columnsArticle in data.get("columns"):
            url = columnsArticle["post_link"]
            title = columnsArticle["post_title"]
            author = columnsArticle["post_author"]
            description = ''
            pubdate = data.get("issue_date")
            columns.append(
                dict(title=title, url=url, date=pubdate, description=description, content='', author=author))
        
        for dailyArticle in data.get("daily_studies"):
            url = dailyArticle["post_link"]
            title = dailyArticle["post_day"] + " " + data.get("issue_date")
            author = ""
            description = ""
            pubdate = dailyArticle["post_day"] + " " + data.get("issue_date")
            dailystudies.append(
                dict(title=title, url=url, date=pubdate, description=description, content='', author=author))


        ans = [('Features', features), ('Columns', columns), ('Daily Studies', dailystudies)]

        return ans

    def postprocess_html(self, soupe, first_fetch):
        for cit in soupe.findAll("div", attrs={"class": re.compile("pull-quote__quote")}):
            cit.name = "blockquote"
            cit['class'] = "tt-quote"
        
        soupe.find("div", attrs={"class": re.compile("article__number")}).find("hr").extract()

        t = soupe.find("svg")
        if t is not None:
            t['width'] = '2em'
            t['height'] = '2em'
            t['fill'] = 'currentColor'
            t['style'] = 'vertical-align: middle;display:inline-block;'
            t['xmlns'] = t['xmlns:xmlns']
            del t['xmlns:xmlns'] #important to avoid xml error on ibooks or Kobo readers

        return soupe
